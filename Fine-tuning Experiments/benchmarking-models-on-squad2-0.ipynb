{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13670431,"sourceType":"datasetVersion","datasetId":8692187},{"sourceId":13673557,"sourceType":"datasetVersion","datasetId":8694304},{"sourceId":13673658,"sourceType":"datasetVersion","datasetId":8694374},{"sourceId":13693035,"sourceType":"datasetVersion","datasetId":8709424},{"sourceId":13714972,"sourceType":"datasetVersion","datasetId":8725178}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Benchmarking DeBERTa-v3-large-squad2 fine tuned on hotpotQA for full answer (4 Layer Unfreeze)**","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets evaluate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T06:59:11.974012Z","iopub.execute_input":"2025-11-13T06:59:11.974492Z","iopub.status.idle":"2025-11-13T06:59:22.614437Z","shell.execute_reply.started":"2025-11-13T06:59:11.974465Z","shell.execute_reply":"2025-11-13T06:59:22.613361Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n\nmodel_path = \"/kaggle/input/deberta-v3-large-squad2-deepset-hotpot-fullanswer/kaggle/working/deberta-v3-large-squad-v2-hotpot\"  # e.g., \"./checkpoints/deberta-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_path)\n\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True    \n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:35:54.567346Z","iopub.execute_input":"2025-11-11T13:35:54.567578Z","iopub.status.idle":"2025-11-11T13:36:38.513186Z","shell.execute_reply.started":"2025-11-11T13:35:54.567555Z","shell.execute_reply":"2025-11-11T13:36:38.512339Z"}},"outputs":[{"name":"stderr","text":"2025-11-11 13:36:06.798744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762868166.986784      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762868167.043670      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:36:38.514426Z","iopub.execute_input":"2025-11-11T13:36:38.515123Z","iopub.status.idle":"2025-11-11T13:36:41.854021Z","shell.execute_reply.started":"2025-11-11T13:36:38.515096Z","shell.execute_reply":"2025-11-11T13:36:41.853483Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfd53249df684fc7b0d0ea4d7a16fe85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea532d264e947178a3cc48a10e2218f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ea409fc8664436a2f3f369d90847d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90506d0a3faf4962b00aa17163fecaac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95af24775eca4a7695fd46231fa2aae4"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:39:47.449139Z","iopub.execute_input":"2025-11-11T13:39:47.449886Z","iopub.status.idle":"2025-11-11T13:56:58.655893Z","shell.execute_reply.started":"2025-11-11T13:39:47.449854Z","shell.execute_reply":"2025-11-11T13:56:58.655257Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"squad_v2\")\nresults = metric.compute(predictions=predictions, references=references)\n\nprint(f\"Exact Match (EM): {results['exact']:.2f}\")\nprint(f\"F1 Score: {results['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:56:58.657323Z","iopub.execute_input":"2025-11-11T13:56:58.657916Z","iopub.status.idle":"2025-11-11T13:57:00.866432Z","shell.execute_reply.started":"2025-11-11T13:56:58.657888Z","shell.execute_reply":"2025-11-11T13:57:00.865628Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1729e0d3af50464e9a13122fe7861235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85851087dc814c5dbf826a3fc2406520"}},"metadata":{}},{"name":"stdout","text":"Exact Match (EM): 21.28\nF1 Score: 40.96\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **Benchmarking DeBERTa-v3-large-squad2 fine tuned on hotpotQA for gold standard Paragraph**","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:05:12.150871Z","iopub.execute_input":"2025-11-10T04:05:12.151359Z","iopub.status.idle":"2025-11-10T04:05:20.872434Z","shell.execute_reply.started":"2025-11-10T04:05:12.151335Z","shell.execute_reply":"2025-11-10T04:05:20.871700Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n\nmodel_path = \"/kaggle/input/deberta-v3-large-squad2-finetune-hotpot-goldpara/debarta-squad-hotpot-final/checkpoint-2000\"  # e.g., \"./checkpoints/deberta-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_path)\n\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:12:11.241021Z","iopub.execute_input":"2025-11-11T14:12:11.241618Z","iopub.status.idle":"2025-11-11T14:12:22.695683Z","shell.execute_reply.started":"2025-11-11T14:12:11.241591Z","shell.execute_reply":"2025-11-11T14:12:22.694903Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:12:22.701215Z","iopub.execute_input":"2025-11-11T14:12:22.701458Z","iopub.status.idle":"2025-11-11T14:12:23.493012Z","shell.execute_reply.started":"2025-11-11T14:12:22.701440Z","shell.execute_reply":"2025-11-11T14:12:23.492186Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:12:23.493765Z","iopub.execute_input":"2025-11-11T14:12:23.493999Z","iopub.status.idle":"2025-11-11T14:29:39.158868Z","shell.execute_reply.started":"2025-11-11T14:12:23.493981Z","shell.execute_reply":"2025-11-11T14:29:39.158245Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"squad_v2\")\nresults = metric.compute(predictions=predictions, references=references)\n\nprint(f\"Exact Match (EM): {results['exact']:.2f}\")\nprint(f\"F1 Score: {results['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:29:39.160549Z","iopub.execute_input":"2025-11-11T14:29:39.160807Z","iopub.status.idle":"2025-11-11T14:29:40.720494Z","shell.execute_reply.started":"2025-11-11T14:29:39.160788Z","shell.execute_reply":"2025-11-11T14:29:40.719826Z"}},"outputs":[{"name":"stdout","text":"Exact Match (EM): 25.65\nF1 Score: 44.65\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **Benchmarking DeBERTa-v3-large fine tune on SQuAD 2.0 (3/4)**","metadata":{}},{"cell_type":"markdown","source":"**For only .pt file model**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, DebertaV2ForQuestionAnswering\n\n# Load saved state dict\nstate = torch.load(\"/kaggle/input/deberta-v3-large-finetune-squad2-0/step24648_epoch0.pt\")\n\n# Load base model and tokenizer\nmodel = DebertaV2ForQuestionAnswering.from_pretrained(\"microsoft/deberta-v3-large\")\nmodel.load_state_dict(state[\"model\"], strict=False)\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:29:40.721333Z","iopub.execute_input":"2025-11-11T14:29:40.721610Z","iopub.status.idle":"2025-11-11T14:30:23.116545Z","shell.execute_reply.started":"2025-11-11T14:29:40.721586Z","shell.execute_reply":"2025-11-11T14:30:23.115872Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da151efbd3849ccae0c9b4adf0cac9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"696c20cd86214ef5af6e0a1c0a73f4ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1ad33e905d441ba8d87268a7ed0eafe"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b94e107fef5d4d90bca76a13286c0704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd7533520074bffac85e0e240d5495e"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nDevice set to use cuda:0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:30:23.121049Z","iopub.execute_input":"2025-11-11T14:30:23.121290Z","iopub.status.idle":"2025-11-11T14:30:23.931580Z","shell.execute_reply.started":"2025-11-11T14:30:23.121273Z","shell.execute_reply":"2025-11-11T14:30:23.931001Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"predictions1 = []\nreferences1 = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions1.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references1.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:30:23.932237Z","iopub.execute_input":"2025-11-11T14:30:23.932436Z","iopub.status.idle":"2025-11-11T14:47:40.188187Z","shell.execute_reply.started":"2025-11-11T14:30:23.932420Z","shell.execute_reply":"2025-11-11T14:47:40.187560Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import evaluate\n\nmetric1 = evaluate.load(\"squad_v2\")\nresults1 = metric1.compute(predictions=predictions1, references=references1)\n\nprint(f\"Exact Match (EM): {results1['exact']:.2f}\")\nprint(f\"F1 Score: {results1['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:47:40.189130Z","iopub.execute_input":"2025-11-11T14:47:40.190023Z","iopub.status.idle":"2025-11-11T14:47:42.138081Z","shell.execute_reply.started":"2025-11-11T14:47:40.189998Z","shell.execute_reply":"2025-11-11T14:47:42.137428Z"}},"outputs":[{"name":"stdout","text":"Exact Match (EM): 84.44\nF1 Score: 87.98\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# **DeBERTa-v3-large-squad2**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n\nmodel_path = \"deepset/deberta-v3-large-squad2\"  # e.g., \"./checkpoints/deberta-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_path)\n\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:20:11.287696Z","iopub.execute_input":"2025-11-11T17:20:11.287941Z","iopub.status.idle":"2025-11-11T17:20:54.737689Z","shell.execute_reply.started":"2025-11-11T17:20:11.287912Z","shell.execute_reply":"2025-11-11T17:20:54.736915Z"}},"outputs":[{"name":"stderr","text":"2025-11-11 17:20:24.262328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762881624.449649      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762881624.525083      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109806ea55a749d39d2a91dc0a103a10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2dc764947fc4d10bccb5c0edf7f0748"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62560b9b06e447dc96a4d97042ef5602"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baa815d5a6ac4facbc5f785a067cc209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dca95394da046288fefd9eddf19f719"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafc98fa17044b2fb7eb04194586cb84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2eb4fef81d547f49429f06c07a7937f"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:20:54.738388Z","iopub.execute_input":"2025-11-11T17:20:54.738900Z","iopub.status.idle":"2025-11-11T17:20:58.178821Z","shell.execute_reply.started":"2025-11-11T17:20:54.738882Z","shell.execute_reply":"2025-11-11T17:20:58.178248Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e24c8697e67450fb2fda907b066475d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aae6703ff2a4e85905eb89d44b9cb69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb0dcaa912b84c71a94bfa25feb267e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"234b032e08fa4687adb44ca4897e51a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd5d643d605a4f6fb79976428919d0b5"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:20:58.180328Z","iopub.execute_input":"2025-11-11T17:20:58.180840Z","iopub.status.idle":"2025-11-11T17:36:58.683784Z","shell.execute_reply.started":"2025-11-11T17:20:58.180821Z","shell.execute_reply":"2025-11-11T17:36:58.682900Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"squad_v2\")\nresults = metric.compute(predictions=predictions, references=references)\n\nprint(f\"Exact Match (EM): {results['exact']:.2f}\")\nprint(f\"F1 Score: {results['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:36:58.684724Z","iopub.execute_input":"2025-11-11T17:36:58.685038Z","iopub.status.idle":"2025-11-11T17:37:00.872221Z","shell.execute_reply.started":"2025-11-11T17:36:58.685014Z","shell.execute_reply":"2025-11-11T17:37:00.871399Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b125f704d8cb403592f4c5f59a00365c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6d08ea304e24474ae2d7100adc397f7"}},"metadata":{}},{"name":"stdout","text":"Exact Match (EM): 87.21\nF1 Score: 90.61\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **BigBird-RoBERTa-large fine tuned on MASHQA**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n\nmodel_path = \"/kaggle/input/bigbird-finetuned-mashqa/bigbird-roberta-large-mashqa\"  # e.g., \"./checkpoints/deberta-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_path)\n\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:37:00.873029Z","iopub.execute_input":"2025-11-11T17:37:00.873253Z","iopub.status.idle":"2025-11-11T17:37:13.999217Z","shell.execute_reply.started":"2025-11-11T17:37:00.873226Z","shell.execute_reply":"2025-11-11T17:37:13.998501Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:37:14.003882Z","iopub.execute_input":"2025-11-11T17:37:14.004088Z","iopub.status.idle":"2025-11-11T17:37:15.108230Z","shell.execute_reply.started":"2025-11-11T17:37:14.004074Z","shell.execute_reply":"2025-11-11T17:37:15.107670Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:37:15.108965Z","iopub.execute_input":"2025-11-11T17:37:15.109183Z","iopub.status.idle":"2025-11-11T17:48:59.699595Z","shell.execute_reply.started":"2025-11-11T17:37:15.109165Z","shell.execute_reply":"2025-11-11T17:48:59.698982Z"}},"outputs":[{"name":"stderr","text":"Attention type 'block_sparse' is not possible if sequence_length: 172 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import evaluate\n\nmetric1 = evaluate.load(\"squad_v2\")\nresults1 = metric1.compute(predictions=predictions, references=references)\n\nprint(f\"Exact Match (EM): {results1['exact']:.2f}\")\nprint(f\"F1 Score: {results1['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:48:59.701555Z","iopub.execute_input":"2025-11-11T17:48:59.701796Z","iopub.status.idle":"2025-11-11T17:49:01.746847Z","shell.execute_reply.started":"2025-11-11T17:48:59.701771Z","shell.execute_reply":"2025-11-11T17:49:01.746219Z"}},"outputs":[{"name":"stdout","text":"Exact Match (EM): 21.43\nF1 Score: 22.51\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **BigBird-RoBERTa-large**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n\nmodel_path = \"google/bigbird-roberta-large\"  # e.g., \"./checkpoints/deberta-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_path)\n\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:49:01.747596Z","iopub.execute_input":"2025-11-11T17:49:01.747811Z","iopub.status.idle":"2025-11-11T17:49:12.055062Z","shell.execute_reply.started":"2025-11-11T17:49:01.747792Z","shell.execute_reply":"2025-11-11T17:49:12.053972Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/969 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a7de8f146d4abb8c980c1eeabfe407"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11aa1adc17dc454ca39a5360a28f8b02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/846k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb21078d02b44ffeb69c7c68a9e8c89c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/775 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60182b8fe11e40bcbf0324b8907fb3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6546a0f7a4b84dafbeedfa9c5d0e7ef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee814767c6c4e12b44896dfcd308d5f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BigBirdForQuestionAnswering were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['qa_classifier.intermediate.dense.bias', 'qa_classifier.intermediate.dense.weight', 'qa_classifier.output.LayerNorm.bias', 'qa_classifier.output.LayerNorm.weight', 'qa_classifier.output.dense.bias', 'qa_classifier.output.dense.weight', 'qa_classifier.qa_outputs.bias', 'qa_classifier.qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cuda:0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:49:12.061595Z","iopub.execute_input":"2025-11-11T17:49:12.062302Z","iopub.status.idle":"2025-11-11T17:49:13.366960Z","shell.execute_reply.started":"2025-11-11T17:49:12.062270Z","shell.execute_reply":"2025-11-11T17:49:13.366071Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:49:13.367745Z","iopub.execute_input":"2025-11-11T17:49:13.368135Z","iopub.status.idle":"2025-11-11T18:00:59.640206Z","shell.execute_reply.started":"2025-11-11T17:49:13.368101Z","shell.execute_reply":"2025-11-11T18:00:59.639579Z"}},"outputs":[{"name":"stderr","text":"Attention type 'block_sparse' is not possible if sequence_length: 172 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import evaluate\n\nmetric1 = evaluate.load(\"squad_v2\")\nresults1 = metric1.compute(predictions=predictions, references=references)\n\nprint(f\"Exact Match (EM): {results1['exact']:.2f}\")\nprint(f\"F1 Score: {results1['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T18:00:59.640985Z","iopub.execute_input":"2025-11-11T18:00:59.641198Z","iopub.status.idle":"2025-11-11T18:01:01.580874Z","shell.execute_reply.started":"2025-11-11T18:00:59.641182Z","shell.execute_reply":"2025-11-11T18:01:01.580113Z"}},"outputs":[{"name":"stdout","text":"Exact Match (EM): 0.08\nF1 Score: 3.20\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# **DeBERTa-v3-large fine tuned on Squad2.0 for 2 Epoch**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, DebertaV2ForQuestionAnswering, pipeline\n\n# Load base model and tokenizer\nmodel = DebertaV2ForQuestionAnswering.from_pretrained(\"microsoft/deberta-v3-large\")\n\n# Load fine-tuned weights (directly)\nstate_dict = torch.load(\"/kaggle/input/deberta-v3-large-squad2-2epoch/best_model.pt\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.load_state_dict(state_dict, strict=False)\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n\n# Move to GPU if available\nmodel.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Create QA pipeline\nqa_pipeline = pipeline(\n    \"question-answering\",\n    model=model,\n    tokenizer=tokenizer,\n    handle_impossible_answer=True,\n    device=0 if torch.cuda.is_available() else -1\n)\n\nprint(\"✅ Model and tokenizer loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:09:09.557100Z","iopub.execute_input":"2025-11-13T07:09:09.557767Z","iopub.status.idle":"2025-11-13T07:09:15.756095Z","shell.execute_reply.started":"2025-11-13T07:09:09.557741Z","shell.execute_reply":"2025-11-13T07:09:15.755459Z"}},"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43db1849879840dfb17cea93750d3cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c327eb0b0f394191a91ab8168d855beb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"✅ Model and tokenizer loaded successfully!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad_dataset = load_dataset(\"squad_v2\")\nsquad_val = squad_dataset[\"validation\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:09:15.757059Z","iopub.execute_input":"2025-11-13T07:09:15.757279Z","iopub.status.idle":"2025-11-13T07:09:19.205563Z","shell.execute_reply.started":"2025-11-13T07:09:15.757255Z","shell.execute_reply":"2025-11-13T07:09:19.205034Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05560fd4f664f0ba691dff7404e92cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f27334158c72424c835b4fe339d36da2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f28cd3e412f4c9781a29733aa1e3f87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932ee3ecaa0441c7a33c86b5584c1267"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c862500fe7549e6a670391bb2d16c72"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"predictions1 = []\nreferences1 = []\n\nfor example in squad_val:\n    context = example[\"context\"]\n    question = example[\"question\"]\n    id_ = example[\"id\"]\n    \n    try:\n        pred = qa_pipeline({\n            \"context\": context,\n            \"question\": question\n        }, handle_impossible_answer=True)  # needed for squad_v2\n        predicted_answer = pred.get(\"answer\", \"\").strip()\n    except:\n        predicted_answer = \"\"\n\n    predictions1.append({\n        \"id\": id_,\n        \"prediction_text\": predicted_answer,\n        \"no_answer_probability\": 0.0  # required but not used\n    })\n\n    references1.append({\n        \"id\": id_,\n        \"answers\": example[\"answers\"]\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:37:32.328545Z","iopub.execute_input":"2025-11-13T07:37:32.328813Z","iopub.status.idle":"2025-11-13T07:52:33.609675Z","shell.execute_reply.started":"2025-11-13T07:37:32.328794Z","shell.execute_reply":"2025-11-13T07:52:33.608777Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import evaluate\n\nmetric1 = evaluate.load(\"squad_v2\")\nresults1 = metric1.compute(predictions=predictions1, references=references1)\n\nprint(f\"Exact Match (EM): {results1['exact']:.2f}\")\nprint(f\"F1 Score: {results1['f1']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:55:58.675582Z","iopub.execute_input":"2025-11-13T07:55:58.675870Z","iopub.status.idle":"2025-11-13T07:56:01.041640Z","shell.execute_reply.started":"2025-11-13T07:55:58.675851Z","shell.execute_reply":"2025-11-13T07:56:01.040914Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500a1abc199f4d5dae2b7fc569e552d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bc4e0967e9c46cdb42abe2924768b8b"}},"metadata":{}},{"name":"stdout","text":"Exact Match (EM): 85.81\nF1 Score: 89.06\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}